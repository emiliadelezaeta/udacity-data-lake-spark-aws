{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14d03a3a",
   "metadata": {},
   "source": [
    "# Sparkify Data Lake with Spark\n",
    "\n",
    "Exploratory data analysis and first version of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "688798bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import configparser\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.types import IntegerType,BooleanType,DateType,DoubleType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403e9cd6",
   "metadata": {},
   "source": [
    "## AWS Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d7e9a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "\n",
    "config.read_file(open(\"dl.cfg\"))\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]= config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]= config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27586d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"s3a://udacity-dend/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fab4f4",
   "metadata": {},
   "source": [
    "## Create spark session with hadoop-aws package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e0de36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                     .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "                     .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e39fa5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-E2NJCVJ:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1e8fa422358>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fab7f18",
   "metadata": {},
   "source": [
    "## Staging Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9104f4e",
   "metadata": {},
   "source": [
    "### Song Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e11b9cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading data from S3 bucket (AWS)\n",
    "df_song =  spark.read.json(INPUT_FILE + \"song_data/A/A/*/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "751c9de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total records\n",
    "df_song.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa6dcf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_song.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16d6a159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# casting some column types\n",
    "df_song = df_song.withColumn(\"year\",df_song.year.cast('integer'))\n",
    "\n",
    "df_song.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e316e524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+---------------+----------------+--------------------+--------+---------+------------------+--------------------+----+\n",
      "|         artist_id|artist_latitude|artist_location|artist_longitude|         artist_name|duration|num_songs|           song_id|               title|year|\n",
      "+------------------+---------------+---------------+----------------+--------------------+--------+---------+------------------+--------------------+----+\n",
      "|ARSUVLW12454A4C8B8|       35.83073|      Tennessee|       -85.97874|Royal Philharmoni...|94.56281|        1|SOBTCUI12A8AE48B70|Faust: Ballet Mus...|   0|\n",
      "+------------------+---------------+---------------+----------------+--------------------+--------+---------+------------------+--------------------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_song.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12877b41",
   "metadata": {},
   "source": [
    "### Log Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40413334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading data from S3 bucket (AWS)\n",
    "df_log = spark.read.json(INPUT_FILE + \"log_data/*/*/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a41f71e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8056"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total records\n",
    "df_log.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e03e55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6820"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter by Page = \"NextSongs\"\n",
    "df_log = df_log[df_log.page == 'NextSong']\n",
    "df_log.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fa07dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_log.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19d9251d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: integer (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: timestamp (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# casting some column types\n",
    "df_log = df_log.withColumn(\"ts\",F.to_timestamp(df_log.ts.cast('bigint')/1000))\n",
    "df_log = df_log.withColumn(\"userId\",df_log.userId.cast('integer'))\n",
    "df_log = df_log.withColumn(\"sessionId\",df_log.userId.cast('integer'))\n",
    "\n",
    "df_log.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81658b2e",
   "metadata": {},
   "source": [
    "## Data Lake Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e7caa3",
   "metadata": {},
   "source": [
    "### Artists table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7835ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting columns necessary to create the dimension table: songs\n",
    "artist_table = df_song.select(df_song.artist_id, df_song.artist_name, df_song.artist_location, \\\n",
    "                              df_song.artist_latitude, df_song.artist_longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4de070e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total records\n",
    "artist_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "160265db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing duplicate records by \"artist_id\"\n",
    "artist_table = artist_table.dropDuplicates(['artist_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd79f602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "587"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total records after removing duplicates\n",
    "artist_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12a7175a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+---------------+----------------+\n",
      "|         artist_id|         artist_name|     artist_location|artist_latitude|artist_longitude|\n",
      "+------------------+--------------------+--------------------+---------------+----------------+\n",
      "|AR06EB01187FB40150|                NOFX|        Berkeley, CA|           null|            null|\n",
      "|AR06XSY1187B9B279E|   Little River Band|Melbourne, Australia|           null|            null|\n",
      "|AR08LXJ1187B9995A4|           Tungtvann|                    |           null|            null|\n",
      "|AR08VNE1187FB45C2F|Dance With A Stra...|                    |           null|            null|\n",
      "|AR0IT221187B999C4D|      The Weathermen|             BELGIUM|       50.50101|         4.47684|\n",
      "|AR0L04E1187B9AE90C|           The Verve|Wigan, Lancashire...|           null|            null|\n",
      "|AR0MWD61187B9B2B12|The (Internationa...|                    |           null|            null|\n",
      "|AR0TKGM1187B98B40E|           Stereolab|              London|       51.50632|        -0.12714|\n",
      "|AR0WQ0N1187FB3AAB9|         The Accüsed|                    |           null|            null|\n",
      "|AR10USD1187B99F3F1|         Silverstein|Burlington, Ontar...|           null|            null|\n",
      "|AR11YJ91187B997A47|                Ayla|      KILLEEN, Texas|           null|            null|\n",
      "|AR16XZ11187B9A97F0|       Blue Mountain|                    |           null|            null|\n",
      "|AR19SOA1187B98F6E6|        Bob Neuwirth|            New York|       40.71455|       -74.00712|\n",
      "|AR1C2IX1187B99BF74|     Broken Spindles|                    |           null|            null|\n",
      "|AR1DATU1187B9A5498|               Patto|                    |           null|            null|\n",
      "|AR1EZLD1187B98C74B|     Biquini Cavadão|                    |           null|            null|\n",
      "|AR1F6T91187FB4D5FE|        Baby Mammoth|       Hull, England|       53.74319|        -0.34592|\n",
      "|AR1FMBJ1187B992A46|            Melotron|                    |           null|            null|\n",
      "|AR1GYND1187B9A9CD3|          Diesel Boy|Santa Rosa, Calif...|       38.43773|      -122.71242|\n",
      "|AR1H1GY1187B991F17|Tasavallan Presid...|                    |           null|            null|\n",
      "+------------------+--------------------+--------------------+---------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#showing an example of the table\n",
    "artist_table.createOrReplaceTempView(\"artist\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM artist\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c993db1",
   "metadata": {},
   "source": [
    "### Song table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08836b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting columns necessary to create the dimension table: songs\n",
    "song_table = df_song.select(df_song.song_id, df_song.title, df_song.artist_id, df_song.year, df_song.duration)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e02ff4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total records\n",
    "song_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f25cd10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing duplicate records by \"song_id\"\n",
    "song_table = song_table.dropDuplicates(['song_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a1c729d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total records after removing duplicates\n",
    "song_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "429139bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+------------------+----+---------+\n",
      "|           song_id|               title|         artist_id|year| duration|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|SOAADAD12A8C13D5B0|One Shot (Album V...|ARQTC851187B9B03AF|2005|263.99302|\n",
      "|SOABCEU12A8C132027|          Cold Waste|ARL6NP61187B98C1FC|2007|385.43628|\n",
      "|SOABWAP12A8C13F82A|           Take Time|AR5LMPY1187FB573FE|1978|258.89914|\n",
      "|SOABYIT12AB0183026|        Vilda vindar|AR98ZSW1187B98E82C|1985|266.13506|\n",
      "|SOAESJW12A8C137CC2|     Musical Episode|AR3PN3R1187FB4CEBD|2005|234.44853|\n",
      "|SOAFBCP12A8C13CC7D|King Of Scurf (20...|ARTC1LV1187B9A4858|1972|301.40036|\n",
      "|SOAFBKM12AB01837A7|          Brain Dead|ARL14X91187FB4CF14|1995| 94.22322|\n",
      "|SOAFLZM12A8C132A2D|        Rock Rumberu|ARG17O11187FB4A8DA|2006|292.17914|\n",
      "|SOAFQQN12A58A7CA7C|      At The Unicorn|ARROV6A1187B9913A7|   0| 245.4722|\n",
      "|SOAFUVR12AB01800F9|         Star Surfer|ARXRKEA11F50C4AE9E|   0|273.55383|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#showing an example of the table\n",
    "song_table.createOrReplaceTempView(\"songs\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM songs\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bff91e",
   "metadata": {},
   "source": [
    "### Users table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2931d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting columns necessary to create the dimension table: users\n",
    "users_table = df_log.select(df_log.userId, df_log.firstName, df_log.lastName, df_log.level, df_log.gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c409d2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6820"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total records\n",
    "users_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "245270fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing duplicate records by \"UserId\"\n",
    "users_table = users_table.dropDuplicates(['userId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "baed0232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total records after removing duplicates\n",
    "users_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d715c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+-----+------+\n",
      "|userId|firstName|lastName|level|gender|\n",
      "+------+---------+--------+-----+------+\n",
      "|     2|  Jizelle|Benjamin| free|     F|\n",
      "|     3|    Isaac|  Valdez| free|     M|\n",
      "|     4|   Alivia| Terrell| free|     F|\n",
      "|     5|   Elijah|   Davis| free|     M|\n",
      "|     6|  Cecilia|   Owens| free|     F|\n",
      "|     7|   Adelyn|  Jordan| free|     F|\n",
      "|     8|   Kaylee| Summers| free|     F|\n",
      "|     9|    Wyatt|   Scott| free|     M|\n",
      "|    10|   Sylvie|    Cruz| free|     F|\n",
      "|    11|Christian|  Porter| free|     F|\n",
      "+------+---------+--------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#showing an example of the table\n",
    "users_table.createOrReplaceTempView(\"users\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM users\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315e100c",
   "metadata": {},
   "source": [
    "### Time table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a74a42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting some columns like year, month, week of the year, etc.. from timestamp colum and creating the time table\n",
    "time_table = df_log.select(df_log.ts\n",
    "                           , F.hour(\"ts\").alias('hour')\n",
    "                           , F.dayofmonth(\"ts\").alias('day')\n",
    "                           , F.weekofyear(\"ts\").alias('week')\n",
    "                           , F.month(\"ts\").alias('month')\n",
    "                           , F.year(\"ts\").alias('year')\n",
    "                           , F.dayofweek(\"ts\").alias('weekday'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82421ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ts: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_table.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba9a50d",
   "metadata": {},
   "source": [
    "### Songsplay Table _(fact table)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df960b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting only the columns necessary from songs table to be used to create the fact table\n",
    "songs_table = df_song.select(df_song.song_id\n",
    "                             , df_song.artist_id\n",
    "                             , df_song.title\n",
    "                             , df_song.artist_name )\n",
    "songs_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b893fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ts: timestamp (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- artist: string (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- sessionId: integer (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting only the columns necessary from logs table to be used to create the fact table\n",
    "events_table = df_log.select(df_log.ts\n",
    "                             , F.year(\"ts\").alias('year')\n",
    "                             , F.month(\"ts\").alias('month')\n",
    "                             , df_log.artist\n",
    "                             , df_log.song\n",
    "                             , df_log.userId\n",
    "                             , df_log.level\n",
    "                             , df_log.sessionId\n",
    "                             , df_log.location\n",
    "                             , df_log.userAgent)\n",
    "events_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86924372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining both dataframes to build the fact table\n",
    "songsplay_table = events_table.join(songs_table\n",
    "                                , (events_table.artist == songs_table.artist_name) & (events_table.song == songs_table.title ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9b4377f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ts: timestamp (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- sessionId: integer (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting only the columns necessary to create the fact table\n",
    "songsplay_table = songsplay_table.select(songsplay_table.ts\n",
    "                                         , songsplay_table.year\n",
    "                                         , songsplay_table.month\n",
    "                                         , songsplay_table.userId\n",
    "                                         , songsplay_table.level\n",
    "                                         , songsplay_table.song_id\n",
    "                                         , songsplay_table.artist_id\n",
    "                                         , songsplay_table.sessionId \n",
    "                                         , songsplay_table.location\n",
    "                                         , songsplay_table.userAgent)\n",
    "\n",
    "songsplay_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3457eaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-----+------+-----+------------------+------------------+---------+--------------------+--------------------+\n",
      "|                  ts|year|month|userId|level|           song_id|         artist_id|sessionId|            location|           userAgent|\n",
      "+--------------------+----+-----+------+-----+------------------+------------------+---------+--------------------+--------------------+\n",
      "|2018-11-21 22:56:...|2018|   11|    15| paid|SOZCTXZ12AB0182364|AR5KOSW1187FB35FF4|       15|Chicago-Napervill...|\"Mozilla/5.0 (X11...|\n",
      "|2018-11-05 18:49:...|2018|   11|    73| paid|SOHDWWH12A6D4F7F6A|ARC0IOF1187FB3F6E6|       73|Tampa-St. Petersb...|\"Mozilla/5.0 (Mac...|\n",
      "|2018-11-13 23:39:...|2018|   11|    55| free|SOXQYSC12A6310E908|AR0L04E1187B9AE90C|       55|Minneapolis-St. P...|\"Mozilla/5.0 (Mac...|\n",
      "|2018-11-16 15:21:...|2018|   11|    85| paid|SOLRYQR12A670215BF|ARNLO5S1187B9B80CC|       85|       Red Bluff, CA|\"Mozilla/5.0 (Mac...|\n",
      "|2018-11-20 18:46:...|2018|   11|    49| paid|SOCHRXB12A8AE48069|ARTDQRC1187FB4EFD4|       49|San Francisco-Oak...|Mozilla/5.0 (Wind...|\n",
      "|2018-11-24 13:43:...|2018|   11|    73| paid|SONQBUB12A6D4F8ED0|ARFCUN31187B9AD578|       73|Tampa-St. Petersb...|\"Mozilla/5.0 (Mac...|\n",
      "|2018-11-29 22:00:...|2018|   11|    80| paid|SOXQYSC12A6310E908|AR0L04E1187B9AE90C|       80|Portland-South Po...|\"Mozilla/5.0 (Mac...|\n",
      "|2018-11-27 19:09:...|2018|   11|    49| paid|SOCHRXB12A8AE48069|ARTDQRC1187FB4EFD4|       49|San Francisco-Oak...|Mozilla/5.0 (Wind...|\n",
      "|2018-11-09 18:55:...|2018|   11|    80| paid|SOAOJYY12A58A7B2F9|ARFVYJI1187B9B8E13|       80|Portland-South Po...|\"Mozilla/5.0 (Mac...|\n",
      "|2018-11-09 20:57:...|2018|   11|    36| paid|SODWXQV12A6310F10D|AR6892W1187B9AC71B|       36|Janesville-Beloit...|\"Mozilla/5.0 (Win...|\n",
      "+--------------------+----+-----+------+-----+------------------+------------------+---------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#showing an example of the table\n",
    "songsplay_table.createOrReplaceTempView(\"songsplay\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM songsplay\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa901ed",
   "metadata": {},
   "source": [
    "## Parquet files \n",
    "\n",
    "Saving pyspark dataframes already created as parquet files in my own machine, some of them with partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92472fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_table.write.mode('overwrite').parquet('data-lake/' + 'artists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5799cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_table.write.mode('overwrite').partitionBy('year', 'artist_id').parquet('data-lake/' + 'songs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b586b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_table.write.mode('overwrite').parquet('data-lake/' + 'users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76c42e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_table.write.mode('overwrite').partitionBy('year', 'month').parquet('data-lake/' + 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed649241",
   "metadata": {},
   "outputs": [],
   "source": [
    "songsplay_table.write.mode('overwrite').partitionBy('year', 'month').parquet('data-lake/' + 'songsplay')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfb1d4e",
   "metadata": {},
   "source": [
    "## Parquet files to S3 (AWS)\n",
    "\n",
    "Previously it is necessary to create a S3 bucket\n",
    "\n",
    "AWS CLI --> ```aws s3 mb s3://udacity-datalake-sparkify-edls --region us-west-2```\n",
    "\n",
    "To configure the AWS CLI following this [AWS Tutorial](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40ef895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE = 's3a://udacity-datalake-sparkify-edls/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e2372c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_table.write.mode('overwrite').parquet(OUTPUT_FILE  + 'artists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f58200",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_table.write.mode('overwrite').partitionBy('year', 'artist_id').parquet(OUTPUT_FILE + 'songs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3d751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_table.write.mode('overwrite').parquet(OUTPUT_FILE + 'users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079c6822",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_table.write.mode('overwrite').partitionBy('year', 'month').parquet(OUTPUT_FILE + 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39296f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "songsplay_table.write.mode('overwrite').partitionBy('year', 'month').parquet(OUTPUT_FILE + 'songsplay')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edbdfc7",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "- Install Spark: [Spark Pre-built for Apache Hadoop 2.7](https://spark.apache.org/downloads.html)\n",
    "\n",
    "- Problems running Hadoop on Windows: [WINUTILS.EXE](https://cwiki.apache.org/confluence/display/HADOOP2/WindowsProblems)\n",
    "\n",
    "- Transform epoch dates: [PySpark dataframe epoch dates](https://stackoverflow.com/questions/49971903/converting-epoch-to-datetime-in-pyspark-data-frame-using-udf)\n",
    "\n",
    "- Join pyspark dataframes with multiples conditions: [PySpark Join With Multiple Columns & Conditions](https://sparkbyexamples.com/pyspark/pyspark-join-two-or-multiple-dataframes/)\n",
    "\n",
    "- SaveMode parquet files: [Append or Overwrite](https://sparkbyexamples.com/pyspark/pyspark-read-and-write-parquet-file/)\n",
    "\n",
    "- Saving parquet files with partitions: [PySpark Partitions](https://sparkbyexamples.com/pyspark/pyspark-partitionby-example/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4f2a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
